# 4.1.7 HashMap

- 标签：Java

---

- 肥的像猪
- 以下为key-value的集合对象，接口为Map，常用的主要有HashMap、TreeMap
- HashMap()初始化
	- 有几个变量，loadFactor=0.75默认，threshold临界。(这里未解决完)
- put(Object key,Object value)
	- 扩容方法是当现有不为null时，扩展为当前的两倍，扩大时对当前Entry对象数组中的数据hash，并填充数组，最后重新设置threshold值
	- 存在景帝啊你的hash问题，可能是a*1+b*2=5//a*4+b=5;....诸如此类或某个地方(int)丢失小数精度，导致hash重复地址，造成hash冲突
	- put方法是当Object key为空时，实例化一个Entry对象，并将next置为当前数组的第一个Entry对象；需要扩容时参考1。而当Object key不为null时，则先获取hash值，遍历数组找到同hash值并且key相等或equals的Entry对象。如果找到则替换次Entry兑现的值，完成put操作，返回旧的数；若果未找到，参考Object key=null的情况
	- HashMap解决hash冲突使用链表的方式，而不是开放定址的方法。现在我来分析一哈最新的JDK1.8的HashMap及性能优化。在JDK1.6，JDK1.7中，HashMap采用位桶+链表实现，即使用链表处理冲突，同一hash值的链表都存储在一个链表里。但是当位于一个桶中的元素较多，即hash值相等的元素较多时，通过key值依次查找的效率较低。而JDK1.8中，HashMap采用位桶+链表+红黑树实现，当链表长度超过阈值（8）时，将链表转换为红黑树，这样大大减少了查找时间。简单说下HashMap的实现原理：首先有一个每个元素都是链表（可能表述不准确）的数组，当添加一个元素（key-value）时，就首先计算元素key的hash值，以此确定插入数组中的位置，但是可能存在同一hash值的元素已经被放在数组同一位置了，这时就添加到同一hash值的元素的后面，他们在数组的同一位置，但是形成了链表，同一各链表上的Hash值是相同的，所以说数组存放的是链表。而当链表长度太长时，链表就转换为红黑树，这样大大提高了查找的效率。 (参考平头小哥 的CSDN 博客,附其他源码分析)[https://blog.csdn.net/bjstyle/article/details/78221429?utm_source=copy] 
- get(Object key)
	- 第一种情况，当key为null，遍历数组找key为null的进行返回对应Entry的value，找不到为null返回；若key不为null，则对key进行hash和按位操作，找到对应的存储位置然后获取次位置对应的Entry对象，后同上
- remove(Object key)
- containsKey(Object key)
	- 通过调用getEntry方法完成，基本同get过程，只是找到匹配范围Entry对象，而containsKey判断返回Entry兑现给是否为null，为null则返回false，不为null则返回ture
- KeySet()
	- 经常被使用来遍历Map的Key对象，调用时Set<T>、Iterator<T>注意期间同其他迭代器的使用不可被更改，否则会抛出ConcurrentHashMap异常
	```java
	/*chapter04/TestKeySet*/

	Set<Integer> rs=hm.keySet();
        for(Integer r:rs){
            System.out.print(r+"    ");
        }
        Iterator<Integer> riter=rs.iterator();
        while(riter.hasNext()){
            System.out.print(riter.next()+"    ");
        }
	```


- 注意要点:
	- HashMap采用数组存储key、value构成的Entry对象，无容量限制；对于同一hash位置上的使用链表存储
	- HashMap基于key hash寻找Entry对象存放到数组的位置，对于hash冲突采用链表的方式来解决
	- HashMap在插入元素时可能会要扩大数组的容量，在扩大容量时需要重新计算hash，并复制到新的数组中
	- HashMap时非线程安全的，在并发场景中如果不包吃足够䣌同步，就容易在执行HashMap.get时进入死循环，将CPU消耗到100%。在并发场景中可通过Collections.synchronizedMap、Collections.unmodifiableMap或自行同步来保障先册亨安全，但这些实现方式通常性能会在高并发时下降迅速，最好的方法仍然时并发中的ConcurrentHashMap
	- HashMap在遍历时无法保证顺序，如果要保证Map中是顺序排列的，最好用TreeMap